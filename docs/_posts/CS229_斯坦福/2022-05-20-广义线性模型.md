---
title: 广义线性模型 GLM
category: CS229_斯坦福
tags: [机器学习]
---

# GLM 是什么

GLM 是一种模型，或者说是建模方法，使用 GLM，可以让把现实中的问题转化为机器学习需要的形式，也就是确定自己需要的假设函数 $h_{\theta}(x)$，从而推出推出所需的最优化目标。需要注意的是，GLM 只能对那些服从指数分布族的问题建模。

# 什么是指数分布族 The exponential family

指数分布族是指一类特殊的概率分布，这些分布都可以被写成

$$
p(y;n)=b(y)exp(\eta ^TT(y)-a(\eta))
$$

的形式。

许多常见的分布都属于指数分布族，也就是说，他们可以改写成上面这种形式。

比如，伯努利分布 $Y\sim Bernoulli(\phi)$：

$$\begin{aligned}
p(y;\phi)&=\phi ^y(1-\phi)^{1-y} \\
&=\exp(y\log(\phi)+(1-y)\log(1-\phi))\\
&=\exp\left(\left(\log\left(\frac{\phi}{1-\phi}\right)\right)y+\log(1-\phi)\right)
\end{aligned}$$

其中，

$$\begin{aligned}
T(y)&=y \\
\eta&=\log \left(\frac{\phi}{1-\phi}\right) \\
a(\eta)&=-\log(1-\phi) \\
&=\log(1+e^\eta) \\
b(y)&=1
\end{aligned}$$

# 如何使用 GLM 构建模型

GLM 模型的核心其实就是三个假设：

1. $y\mid x;\theta\sim \mathrm{ExpotentialFamily}(\eta)$
2. 给定 $x$（也就是特征），我们预测的目标是 $T(y)$ 的期望，通常情况下有 $T(y)=y$，所以我们的假设函数就是 $h(x)=\mathrm{E}\left[y\mid x\right]$。
3. 参数 $\eta$ 和输入 $x$ 是线性关系：$\eta = \theta ^T x$

# 举例

## 线性回归的推导

如果给定 $x$ 的情况下，$Y\sim\mathcal{N}(\mu,\sigma^2)$：

$$\begin{aligned}
p(y;\mu)&=\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{1}{2}(y-\mu)^2\right) \\
&=\frac{1}{\sqrt{2\pi}}\exp\left(-\frac{1}{2}y^2\right)\cdot\exp\left(\mu y-\frac{1}{2}\mu^2\right) \\
\\
\eta&=\mu \\
T(y)&=y \\
a(\eta)&=\mu^2/2 \\
&=\eta^2/2\\
b(y)&=(1/\sqrt{2\pi})\exp(-y^2/2)
\end{aligned}$$

所以假设函数为：

$$\begin{aligned}
h_\theta(x)&=E[y\mid x;\theta] \\
&=\mu \\
&=\eta \\
&=\theta^Tx
\end{aligned}$$

正好是线性回归的假设函数。

## 逻辑回归的推导

如果给定 $x$ 的情况下，$Y\sim Bernoulli(\phi)$：

从上面的推导可得：

$$\begin{aligned}
\eta&=\log \left(\frac{\phi}{1-\phi}\right) \\
\phi&=\frac{1}{1-e^{-\eta}}
\end{aligned}$$

从而，假设函数为：

$$\begin{aligned}
h_\theta(x)&=\mathrm{E}\left[y\mid x;\theta\right] \\
&=\phi \\
&=1/(1+e^{-\eta}) \\
&=1/(1+e^{-\theta ^T x})
\end{aligned}$$

正好就是 Logistic 回归的形式！